{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "base_path = '../dataset'\n",
    "\n",
    "original_data = os.path.join(base_path, 'original_data')\n",
    "processed_data = os.path.join(base_path, 'processed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [19],\n",
       "       [20]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_items=pd.read_csv(os.path.join(original_data, \"candidate_items.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "candidate_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [8],\n",
       "       [9]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions_items=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "train_sessions_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_purchases_items=pd.read_csv(os.path.join(original_data,\"train_purchases.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "train_purchases_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3],\n",
       "       [ 4],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [19]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sessions_items=pd.read_csv(os.path.join(original_data,\"test_final_sessions.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "test_sessions_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [19],\n",
       "       [20]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sessions_leaderboard_items=pd.read_csv(os.path.join(original_data,\"test_leaderboard_sessions.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "test_sessions_leaderboard_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_test_items = np.concatenate((test_sessions_leaderboard_items, test_sessions_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  313,   366,   575,  1152,  1364,  1883,  2497,  2523,  2677,\n",
       "        2694,  3185,  3529,  3754,  3835,  4042,  4514,  5214,  5394,\n",
       "        6171,  6853,  6873,  6916,  7204,  7780,  8758,  8771,  9384,\n",
       "        9418,  9589, 10463, 10671, 11125, 11933, 12667, 13376, 13618,\n",
       "       13943, 13972, 14395, 14622, 14723, 14967, 15601, 15629, 16206,\n",
       "       17046, 17206, 18482, 18690, 18837, 19637, 21241, 21444, 21904,\n",
       "       21927, 21998, 22030, 22316, 22703, 22746, 24303, 25035, 25277,\n",
       "       25521, 26232, 26742, 27377, 27728, 27826], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InTestButNotInTrain=np.setdiff1d(total_test_items,train_sessions_items)\n",
    "InTestButNotInTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69  items are in test sessions but not in train\n"
     ]
    }
   ],
   "source": [
    "print(len(InTestButNotInTrain),\" items are in test sessions but not in train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(InTestButNotInTrain,train_purchases_items)\n",
    "#None of those 67 items is seen in the train_purchases, so they are unknown items, should be treated in a special way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  221,   313,   344,   366,   575,   950,  1152,  1222,  1364,\n",
       "        1883,  1935,  2411,  2489,  2497,  2523,  2621,  2677,  2694,\n",
       "        3185,  3220,  3529,  3754,  3835,  4042,  4514,  6171,  6425,\n",
       "        6512,  6853,  6873,  6916,  7204,  7321,  7408,  7710,  7780,\n",
       "        8053,  8758,  8814,  8839,  8928,  9384,  9418,  9589,  9974,\n",
       "       10463, 10491, 10496, 10671, 10694, 11125, 11862, 11933, 12438,\n",
       "       12641, 12667, 13376, 13550, 13618, 13788, 13943, 13972, 14167,\n",
       "       14395, 14535, 14723, 15629, 15719, 16045, 16092, 16206, 16800,\n",
       "       17046, 17057, 17206, 17371, 17534, 17576, 17950, 18837, 19808,\n",
       "       20237, 21056, 21241, 21444, 21599, 21904, 21998, 22096, 22143,\n",
       "       22316, 22583, 22703, 22746, 22838, 23640, 23981, 24239, 24303,\n",
       "       25035, 25179, 25277, 25298, 25521, 26201, 26232, 26742, 27042,\n",
       "       27377, 27427, 27728, 27826, 27847], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CandidateNeverBoughtInTrainingSet=np.setdiff1d(candidate_items,train_purchases_items)\n",
    "CandidateNeverBoughtInTrainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CandidateNeverBoughtInTrainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  221,   344,   950,  1222,  1935,  2411,  2489,  2621,  3220,\n",
       "        6425,  6512,  7321,  7408,  7710,  8053,  8839,  8928,  9974,\n",
       "       10491, 10496, 10694, 11862, 12438, 12641, 13550, 13788, 14167,\n",
       "       14535, 15719, 16045, 16092, 16800, 17057, 17371, 17534, 17950,\n",
       "       19808, 21056, 21599, 22096, 22143, 22583, 22838, 23640, 23981,\n",
       "       24239, 25179, 25298, 27042, 27427, 27847], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeenInTrainSessions=np.intersect1d(CandidateNeverBoughtInTrainingSet,train_sessions_items)\n",
    "SeenInTrainSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SeenInTrainSessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data=np.concatenate((candidate_items,train_purchases_items,train_sessions_items,test_sessions_items,test_sessions_leaderboard_items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=[\"item_id\"],data=data,index=[i for i,_ in enumerate(data)]).drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23691 entries, 0 to 23690\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   index    23691 non-null  int64\n",
      " 1   item_id  23691 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 370.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"code\"]=df.index\n",
    "df[\"code\"]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(processed_data,\"map.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:19021].to_csv(os.path.join(processed_data,\"map_purchases.csv\"),index=False) # Mapping of only bought items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"),parse_dates=['date'], \n",
    "                         infer_datetime_format=True,header=0)\n",
    "                         \n",
    "train_sessions_ids=train_sessions.sort_values(\"date\").drop_duplicates(\"session_id\",keep='first')[\"session_id\"]\n",
    "train_sessions_ids=train_sessions_ids.reset_index()\n",
    "train_sessions_ids[\"index\"]=train_sessions_ids.index\n",
    "train_sessions_ids.to_csv(os.path.join(processed_data,\"sessions_map.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_sessions=pd.read_csv(os.path.join(original_data,\"test_final_sessions.csv\"))\n",
    "test_leaderboard_sessions=pd.read_csv(os.path.join(original_data,\"test_leaderboard_sessions.csv\"))\n",
    "test_sessions=pd.concat([test_final_sessions,test_leaderboard_sessions],axis=0)\n",
    "\n",
    "test_sessions_ids=test_sessions.sort_values(\"date\").drop_duplicates(\"session_id\",keep='first')[\"session_id\"]\n",
    "test_sessions_ids=test_sessions_ids.reset_index()\n",
    "test_sessions_ids[\"index\"]=test_sessions_ids.index\n",
    "test_sessions_ids.to_csv(os.path.join(processed_data,\"test_sessions_map.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_items=pd.read_csv(os.path.join(original_data,\"candidate_items.csv\"))\n",
    "candidate_items=candidate_items.merge(df,on=\"item_id\",how=\"left\")\n",
    "candidate_items[\"item_id\"]=candidate_items[\"code\"]\n",
    "del candidate_items[\"code\"]\n",
    "candidate_items.to_csv(os.path.join(processed_data,\"candidate_items_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_sessions=pd.read_csv(os.path.join(original_data,\"test_final_sessions.csv\"))\n",
    "test_final_sessions=test_final_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "test_final_sessions[\"item_id\"]=test_final_sessions[\"code\"]\n",
    "del test_final_sessions[\"code\"]\n",
    "test_final_sessions=test_final_sessions.merge(test_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "test_final_sessions[\"session_id\"]=test_final_sessions[\"index\"]\n",
    "del test_final_sessions[\"index\"]\n",
    "test_final_sessions.to_csv(os.path.join(processed_data,\"test_final_sessions_full_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_sessions=pd.read_csv(os.path.join(original_data,\"test_final_sessions.csv\"))\n",
    "test_final_sessions=test_final_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "test_final_sessions[\"item_id\"]=test_final_sessions[\"code\"]\n",
    "del test_final_sessions[\"code\"]\n",
    "test_final_sessions.to_csv(os.path.join(processed_data,\"test_final_sessions_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leaderboard_sessions=pd.read_csv(os.path.join(original_data,\"test_leaderboard_sessions.csv\"))\n",
    "test_leaderboard_sessions=test_leaderboard_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "test_leaderboard_sessions[\"item_id\"]=test_leaderboard_sessions[\"code\"]\n",
    "del test_leaderboard_sessions[\"code\"]\n",
    "test_leaderboard_sessions=test_leaderboard_sessions.merge(test_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "test_leaderboard_sessions[\"session_id\"]=test_leaderboard_sessions[\"index\"]\n",
    "del test_leaderboard_sessions[\"index\"]\n",
    "test_leaderboard_sessions.to_csv(os.path.join(processed_data,\"test_leaderboard_sessions_full_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leaderboard_sessions=pd.read_csv(os.path.join(original_data,\"test_leaderboard_sessions.csv\"))\n",
    "test_leaderboard_sessions=test_leaderboard_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "test_leaderboard_sessions[\"item_id\"]=test_leaderboard_sessions[\"code\"]\n",
    "del test_leaderboard_sessions[\"code\"]\n",
    "test_leaderboard_sessions.to_csv(os.path.join(processed_data,\"test_leaderboard_sessions_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases=pd.read_csv(os.path.join(original_data,\"train_purchases.csv\"))\n",
    "train_purchases=train_purchases.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_purchases[\"item_id\"]=train_purchases[\"code\"]\n",
    "del train_purchases[\"code\"]\n",
    "train_purchases=train_purchases.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_purchases[\"session_id\"]=train_purchases[\"index\"]\n",
    "del train_purchases[\"index\"]\n",
    "train_purchases.to_csv(os.path.join(processed_data,\"train_purchases_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"))\n",
    "train_sessions=train_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_sessions[\"item_id\"]=train_sessions[\"code\"]\n",
    "del train_sessions[\"code\"]\n",
    "train_sessions=train_sessions.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_sessions[\"session_id\"]=train_sessions[\"index\"]\n",
    "del train_sessions[\"index\"]\n",
    "train_sessions.to_csv(os.path.join(processed_data,\"train_sessions_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item_features=pd.read_csv(os.path.join(original_data,\"item_features.csv\"))\n",
    "item_features=item_features.merge(df,on=\"item_id\",how=\"left\")\n",
    "item_features[\"item_id\"]=item_features[\"code\"]\n",
    "del item_features[\"code\"]\n",
    "item_features.to_csv(os.path.join(processed_data,\"item_features_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"),parse_dates=['date'], \n",
    "                         infer_datetime_format=True,header=0)\n",
    "\n",
    "\n",
    "last_month_start = datetime.strptime(\"01/05/21 00:00:00\", '%d/%m/%y %H:%M:%S')\n",
    "\n",
    "train_sessions_train_split=train_sessions[train_sessions[\"date\"]<last_month_start]\n",
    "\n",
    "\n",
    "train_sessions_train_split=train_sessions_train_split.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_sessions_train_split[\"item_id\"]=train_sessions_train_split[\"code\"]\n",
    "del train_sessions_train_split[\"code\"]\n",
    "train_sessions_train_split=train_sessions_train_split.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_sessions_train_split[\"session_id\"]=train_sessions_train_split[\"index\"]\n",
    "del train_sessions_train_split[\"index\"]\n",
    "train_sessions_train_split.to_csv(os.path.join(processed_data,\"train_sessions_train_split_mapped.csv\"),index=False)\n",
    "\n",
    "train_sessions_valid_split=train_sessions[train_sessions[\"date\"]>=last_month_start]\n",
    "\n",
    "\n",
    "train_sessions_valid_split=train_sessions_valid_split.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_sessions_valid_split[\"item_id\"]=train_sessions_valid_split[\"code\"]\n",
    "del train_sessions_valid_split[\"code\"]\n",
    "train_sessions_valid_split=train_sessions_valid_split.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_sessions_valid_split[\"session_id\"]=train_sessions_valid_split[\"index\"]\n",
    "del train_sessions_valid_split[\"index\"]\n",
    "train_sessions_valid_split.to_csv(os.path.join(processed_data,\"train_sessions_valid_split_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases=pd.read_csv(os.path.join(original_data,\"train_purchases.csv\"),parse_dates=['date'], \n",
    "                         infer_datetime_format=True,header=0)\n",
    "\n",
    "\n",
    "last_month_start = datetime.strptime(\"01/05/21 00:00:00\", '%d/%m/%y %H:%M:%S')\n",
    "\n",
    "train_purchases_train_split=train_purchases[train_purchases[\"date\"]<last_month_start]\n",
    "\n",
    "\n",
    "train_purchases_train_split=train_purchases_train_split.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_purchases_train_split[\"item_id\"]=train_purchases_train_split[\"code\"]\n",
    "del train_purchases_train_split[\"code\"]\n",
    "train_purchases_train_split=train_purchases_train_split.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_purchases_train_split[\"session_id\"]=train_purchases_train_split[\"index\"]\n",
    "del train_purchases_train_split[\"index\"]\n",
    "train_purchases_train_split.to_csv(os.path.join(processed_data,\"train_purchases_train_split_mapped.csv\"),index=False)\n",
    "\n",
    "train_purchases_valid_split=train_purchases[train_purchases[\"date\"]>=last_month_start]\n",
    "\n",
    "\n",
    "train_purchases_valid_split=train_purchases_valid_split.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_purchases_valid_split[\"item_id\"]=train_purchases_valid_split[\"code\"]\n",
    "del train_purchases_valid_split[\"code\"]\n",
    "train_purchases_valid_split=train_purchases_valid_split.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_purchases_valid_split[\"session_id\"]=train_purchases_valid_split[\"index\"]\n",
    "del train_purchases_valid_split[\"index\"]\n",
    "train_purchases_valid_split.to_csv(os.path.join(processed_data,\"train_purchases_valid_split_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    \n",
    "    \n",
    "    df_URM['count']=1\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)),shape=(1000000,23692))\n",
    "\n",
    "    \n",
    "\n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions_seen = get_URM()\n",
    "train_bought = get_URM(\"train_purchases_train_split_mapped.csv\")\n",
    "\n",
    "valid_sessions_seen= get_URM(\"train_sessions_valid_split_mapped.csv\")\n",
    "valid_bought = get_URM(\"train_purchases_valid_split_mapped.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.save_npz(os.path.join(processed_data, \"URM_train_seen.npz\"), train_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_train_bought.npz\"), train_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_valid_seen.npz\"), valid_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_valid_bought.npz\"), valid_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_train_full.npz\"), train_sessions_seen+train_bought)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_valid_full.npz\"), valid_sessions_seen+valid_bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM_test(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    \n",
    "    \n",
    "    df_URM['count']=1\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)))\n",
    "\n",
    "    \n",
    "\n",
    "    return URM,np.unique(session_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leaderboard,leaderboard_sessions = get_URM_test(file=\"test_leaderboard_sessions_mapped.csv\")\n",
    "\n",
    "test_final,final_sessions = get_URM_test(file=\"test_final_sessions_mapped.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.save_npz(os.path.join(processed_data, \"URM_test_leaderboard.npz\"), test_leaderboard)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_test_final.npz\"), test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(processed_data, \"leaderboard_sessions_ids\"),leaderboard_sessions)\n",
    "np.save(os.path.join(processed_data, \"final_sessions_ids\"),final_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM_temporal_decay(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False,temperature=30,last_date=datetime.strptime(\"01/05/21 00:00:00\", '%d/%m/%y %H:%M:%S')):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    df_URM[\"diff\"] = last_date-df_URM[\"date\"]\n",
    "    df_URM[\"days\"] = df_URM[\"diff\"].dt.days\n",
    "    df_URM[\"days\"] = df_URM[\"days\"].apply(lambda x: max(0,x))\n",
    "    df_URM[\"count\"] = df_URM[\"days\"].apply(lambda x: np.exp(-x/temperature))\n",
    "    print(df_URM.head(10))\n",
    "\n",
    "\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)),shape=(1000000,23692))\n",
    "\n",
    "    \n",
    "    print(\"computed\")\n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                    date                     diff  days  \\\n",
      "0      663204     9769 2020-12-18 21:25:00.373 133 days 02:34:59.627000   133   \n",
      "1      663204     9769 2020-12-18 21:19:48.093 133 days 02:40:11.907000   133   \n",
      "2       85375    12783 2020-03-13 19:35:27.136 413 days 04:24:32.864000   413   \n",
      "3      374472    14116 2020-08-26 19:18:30.833 247 days 04:41:29.167000   247   \n",
      "4      374472     6166 2020-08-26 19:16:31.211 247 days 04:43:28.789000   247   \n",
      "5      374472     6924 2020-08-26 19:15:47.232 247 days 04:44:12.768000   247   \n",
      "6      526578     4546 2020-11-02 16:31:18.543 179 days 07:28:41.457000   179   \n",
      "7      526578     8092 2020-11-02 16:34:33.794 179 days 07:25:26.206000   179   \n",
      "8      526578    17752 2020-11-02 16:43:04.022 179 days 07:16:55.978000   179   \n",
      "9      526578    14975 2020-11-02 16:42:02.287 179 days 07:17:57.713000   179   \n",
      "\n",
      "      count  \n",
      "0  0.011875  \n",
      "1  0.011875  \n",
      "2  0.000001  \n",
      "3  0.000266  \n",
      "4  0.000266  \n",
      "5  0.000266  \n",
      "6  0.002563  \n",
      "7  0.002563  \n",
      "8  0.002563  \n",
      "9  0.002563  \n",
      "computed\n",
      "   session_id  item_id                    date                     diff  days  \\\n",
      "0      663204    12492 2020-12-18 21:26:47.986 133 days 02:33:12.014000   133   \n",
      "1       85375     3299 2020-03-13 19:36:15.507 413 days 04:23:44.493000   413   \n",
      "2      374472    17411 2020-08-26 19:20:32.049 247 days 04:39:27.951000   247   \n",
      "3      526578    11229 2020-11-02 17:16:45.920 179 days 06:43:14.080000   179   \n",
      "4       66630    11568 2020-02-26 18:27:44.114 429 days 05:32:15.886000   429   \n",
      "5      192688    18172 2020-05-18 12:52:09.764 347 days 11:07:50.236000   347   \n",
      "6      895749     1512 2021-04-20 19:46:42.594  10 days 04:13:17.406000    10   \n",
      "7      257246    12205 2020-06-21 10:33:22.535 313 days 13:26:37.465000   313   \n",
      "8      789144     2124 2021-03-01 15:17:04.264  60 days 08:42:55.736000    60   \n",
      "9      580394     6925 2020-11-27 20:46:08.951 154 days 03:13:51.049000   154   \n",
      "\n",
      "          count  \n",
      "0  1.187484e-02  \n",
      "1  1.050056e-06  \n",
      "2  2.656494e-04  \n",
      "3  2.562770e-03  \n",
      "4  6.160116e-07  \n",
      "5  9.476773e-06  \n",
      "6  7.165313e-01  \n",
      "7  2.943479e-05  \n",
      "8  1.353353e-01  \n",
      "9  5.896871e-03  \n",
      "computed\n",
      "   session_id  item_id                    date                      diff  \\\n",
      "0      929236      417 2021-05-05 13:19:15.147  -5 days +10:40:44.853000   \n",
      "1      929236     3054 2021-05-05 14:13:21.645  -5 days +09:46:38.355000   \n",
      "2      929236     2780 2021-05-05 13:19:54.211  -5 days +10:40:05.789000   \n",
      "3      929236    14829 2021-05-05 13:18:49.495  -5 days +10:41:10.505000   \n",
      "4      929236     3746 2021-05-05 14:03:43.401  -5 days +09:56:16.599000   \n",
      "5      929236     1139 2021-05-05 13:18:20.994  -5 days +10:41:39.006000   \n",
      "6      984653     2950 2021-05-27 10:14:06.491 -27 days +13:45:53.509000   \n",
      "7      984653     3491 2021-05-27 10:14:01.136 -27 days +13:45:58.864000   \n",
      "8      984653     2821 2021-05-27 10:13:55.930 -27 days +13:46:04.070000   \n",
      "9      984653     3491 2021-05-27 10:13:40.996 -27 days +13:46:19.004000   \n",
      "\n",
      "   days  count  \n",
      "0     0    1.0  \n",
      "1     0    1.0  \n",
      "2     0    1.0  \n",
      "3     0    1.0  \n",
      "4     0    1.0  \n",
      "5     0    1.0  \n",
      "6     0    1.0  \n",
      "7     0    1.0  \n",
      "8     0    1.0  \n",
      "9     0    1.0  \n",
      "computed\n",
      "   session_id  item_id                    date                      diff  \\\n",
      "0      929236     3732 2021-05-05 14:15:07.278  -5 days +09:44:52.722000   \n",
      "1      984653     4579 2021-05-27 10:24:05.043 -27 days +13:35:54.957000   \n",
      "2      998452     1605 2021-05-31 13:44:52.368 -31 days +10:15:07.632000   \n",
      "3      928718      806 2021-05-05 10:11:06.926  -5 days +13:48:53.074000   \n",
      "4      980028     4503 2021-05-25 16:24:30.224 -25 days +07:35:29.776000   \n",
      "5      970090     2620 2021-05-21 18:12:17.106 -21 days +05:47:42.894000   \n",
      "6      987395     1972 2021-05-28 08:35:35.820 -28 days +15:24:24.180000   \n",
      "7      952246     2725 2021-05-14 19:53:25.760 -14 days +04:06:34.240000   \n",
      "8      951522     1790 2021-05-14 17:48:41.203 -14 days +06:11:18.797000   \n",
      "9      961516     2483 2021-05-18 13:16:44.633 -18 days +10:43:15.367000   \n",
      "\n",
      "   days  count  \n",
      "0     0    1.0  \n",
      "1     0    1.0  \n",
      "2     0    1.0  \n",
      "3     0    1.0  \n",
      "4     0    1.0  \n",
      "5     0    1.0  \n",
      "6     0    1.0  \n",
      "7     0    1.0  \n",
      "8     0    1.0  \n",
      "9     0    1.0  \n",
      "computed\n"
     ]
    }
   ],
   "source": [
    "train_sessions_seen = get_URM_temporal_decay()\n",
    "train_bought = get_URM_temporal_decay(\"train_purchases_train_split_mapped.csv\")\n",
    "\n",
    "valid_sessions_seen= get_URM_temporal_decay(\"train_sessions_valid_split_mapped.csv\")\n",
    "valid_bought = get_URM_temporal_decay(\"train_purchases_valid_split_mapped.csv\")\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_train_seen.npz\"), train_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_train_bought.npz\"), train_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_valid_seen.npz\"), valid_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_valid_bought.npz\"), valid_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_train_full.npz\"), train_sessions_seen+train_bought)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_valid_full.npz\"), valid_sessions_seen+valid_bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                    date                     diff  days  \\\n",
      "0      663204     9769 2020-12-18 21:25:00.373 164 days 02:34:59.627000   164   \n",
      "1      663204     9769 2020-12-18 21:19:48.093 164 days 02:40:11.907000   164   \n",
      "2       85375    12783 2020-03-13 19:35:27.136 444 days 04:24:32.864000   444   \n",
      "3      374472    14116 2020-08-26 19:18:30.833 278 days 04:41:29.167000   278   \n",
      "4      374472     6166 2020-08-26 19:16:31.211 278 days 04:43:28.789000   278   \n",
      "5      374472     6924 2020-08-26 19:15:47.232 278 days 04:44:12.768000   278   \n",
      "6      526578     4546 2020-11-02 16:31:18.543 210 days 07:28:41.457000   210   \n",
      "7      526578     8092 2020-11-02 16:34:33.794 210 days 07:25:26.206000   210   \n",
      "8      526578    17752 2020-11-02 16:43:04.022 210 days 07:16:55.978000   210   \n",
      "9      526578    14975 2020-11-02 16:42:02.287 210 days 07:17:57.713000   210   \n",
      "\n",
      "          count  \n",
      "0  4.225293e-03  \n",
      "1  4.225293e-03  \n",
      "2  3.736299e-07  \n",
      "3  9.452307e-05  \n",
      "4  9.452307e-05  \n",
      "5  9.452307e-05  \n",
      "6  9.118820e-04  \n",
      "7  9.118820e-04  \n",
      "8  9.118820e-04  \n",
      "9  9.118820e-04  \n",
      "computed\n",
      "   session_id  item_id                    date                     diff  days  \\\n",
      "0      663204    12492 2020-12-18 21:26:47.986 164 days 02:33:12.014000   164   \n",
      "1       85375     3299 2020-03-13 19:36:15.507 444 days 04:23:44.493000   444   \n",
      "2      374472    17411 2020-08-26 19:20:32.049 278 days 04:39:27.951000   278   \n",
      "3      526578    11229 2020-11-02 17:16:45.920 210 days 06:43:14.080000   210   \n",
      "4       66630    11568 2020-02-26 18:27:44.114 460 days 05:32:15.886000   460   \n",
      "5      192688    18172 2020-05-18 12:52:09.764 378 days 11:07:50.236000   378   \n",
      "6      895749     1512 2021-04-20 19:46:42.594  41 days 04:13:17.406000    41   \n",
      "7      257246    12205 2020-06-21 10:33:22.535 344 days 13:26:37.465000   344   \n",
      "8      789144     2124 2021-03-01 15:17:04.264  91 days 08:42:55.736000    91   \n",
      "9      580394     6925 2020-11-27 20:46:08.951 185 days 03:13:51.049000   185   \n",
      "\n",
      "          count  \n",
      "0  4.225293e-03  \n",
      "1  3.736299e-07  \n",
      "2  9.452307e-05  \n",
      "3  9.118820e-04  \n",
      "4  2.191886e-07  \n",
      "5  3.372015e-06  \n",
      "6  2.549554e-01  \n",
      "7  1.047345e-05  \n",
      "8  4.815485e-02  \n",
      "9  2.098218e-03  \n",
      "computed\n",
      "   session_id  item_id                    date                    diff  days  \\\n",
      "0      929236      417 2021-05-05 13:19:15.147 26 days 10:40:44.853000    26   \n",
      "1      929236     3054 2021-05-05 14:13:21.645 26 days 09:46:38.355000    26   \n",
      "2      929236     2780 2021-05-05 13:19:54.211 26 days 10:40:05.789000    26   \n",
      "3      929236    14829 2021-05-05 13:18:49.495 26 days 10:41:10.505000    26   \n",
      "4      929236     3746 2021-05-05 14:03:43.401 26 days 09:56:16.599000    26   \n",
      "5      929236     1139 2021-05-05 13:18:20.994 26 days 10:41:39.006000    26   \n",
      "6      984653     2950 2021-05-27 10:14:06.491  4 days 13:45:53.509000     4   \n",
      "7      984653     3491 2021-05-27 10:14:01.136  4 days 13:45:58.864000     4   \n",
      "8      984653     2821 2021-05-27 10:13:55.930  4 days 13:46:04.070000     4   \n",
      "9      984653     3491 2021-05-27 10:13:40.996  4 days 13:46:19.004000     4   \n",
      "\n",
      "      count  \n",
      "0  0.420350  \n",
      "1  0.420350  \n",
      "2  0.420350  \n",
      "3  0.420350  \n",
      "4  0.420350  \n",
      "5  0.420350  \n",
      "6  0.875173  \n",
      "7  0.875173  \n",
      "8  0.875173  \n",
      "9  0.875173  \n",
      "computed\n",
      "   session_id  item_id                    date                    diff  days  \\\n",
      "0      929236     3732 2021-05-05 14:15:07.278 26 days 09:44:52.722000    26   \n",
      "1      984653     4579 2021-05-27 10:24:05.043  4 days 13:35:54.957000     4   \n",
      "2      998452     1605 2021-05-31 13:44:52.368  0 days 10:15:07.632000     0   \n",
      "3      928718      806 2021-05-05 10:11:06.926 26 days 13:48:53.074000    26   \n",
      "4      980028     4503 2021-05-25 16:24:30.224  6 days 07:35:29.776000     6   \n",
      "5      970090     2620 2021-05-21 18:12:17.106 10 days 05:47:42.894000    10   \n",
      "6      987395     1972 2021-05-28 08:35:35.820  3 days 15:24:24.180000     3   \n",
      "7      952246     2725 2021-05-14 19:53:25.760 17 days 04:06:34.240000    17   \n",
      "8      951522     1790 2021-05-14 17:48:41.203 17 days 06:11:18.797000    17   \n",
      "9      961516     2483 2021-05-18 13:16:44.633 13 days 10:43:15.367000    13   \n",
      "\n",
      "      count  \n",
      "0  0.420350  \n",
      "1  0.875173  \n",
      "2  1.000000  \n",
      "3  0.420350  \n",
      "4  0.818731  \n",
      "5  0.716531  \n",
      "6  0.904837  \n",
      "7  0.567414  \n",
      "8  0.567414  \n",
      "9  0.648344  \n",
      "computed\n"
     ]
    }
   ],
   "source": [
    "train_sessions_seen = get_URM_temporal_decay(last_date=datetime.strptime(\"01/06/21 00:00:00\", '%d/%m/%y %H:%M:%S'))\n",
    "train_bought = get_URM_temporal_decay(\"train_purchases_train_split_mapped.csv\",last_date=datetime.strptime(\"01/06/21 00:00:00\", '%d/%m/%y %H:%M:%S'))\n",
    "\n",
    "valid_sessions_seen= get_URM_temporal_decay(\"train_sessions_valid_split_mapped.csv\",last_date=datetime.strptime(\"01/06/21 00:00:00\", '%d/%m/%y %H:%M:%S'))\n",
    "valid_bought = get_URM_temporal_decay(\"train_purchases_valid_split_mapped.csv\",last_date=datetime.strptime(\"01/06/21 00:00:00\", '%d/%m/%y %H:%M:%S'))\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_train_seen.npz\"), train_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_train_bought.npz\"), train_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_valid_seen.npz\"), valid_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_valid_bought.npz\"), valid_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_train_full.npz\"), train_sessions_seen+train_bought)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_valid_full.npz\"), valid_sessions_seen+valid_bought)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM_temporal_decay_within_session(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False,temperature=5,seen=False):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    df_URM[\"idx\"] = df_URM.index\n",
    "\n",
    "    temp=df_URM.groupby([\"session_id\"])[\"idx\"].max().reset_index()\n",
    "    \n",
    "    temp.rename(columns={\"idx\":\"idx_max\"},inplace=True)\n",
    "    df_URM=df_URM.merge(temp,on=\"session_id\",how=\"left\")\n",
    "    df_URM[\"idx\"]=df_URM[\"idx_max\"]-df_URM[\"idx\"] + 1 if seen else 0\n",
    "    df_URM[\"count\"] = df_URM[\"idx\"].apply(lambda x: np.exp(-x/temperature))\n",
    "    print(df_URM.head(10))\n",
    "\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)),shape=(1000000,23692))\n",
    "\n",
    "    print(\"computed\")\n",
    "\n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                    date  idx  idx_max  count\n",
      "0      663204     9769 2020-12-18 21:25:00.373    0        1    1.0\n",
      "1      663204     9769 2020-12-18 21:19:48.093    0        1    1.0\n",
      "2       85375    12783 2020-03-13 19:35:27.136    0        2    1.0\n",
      "3      374472    14116 2020-08-26 19:18:30.833    0        5    1.0\n",
      "4      374472     6166 2020-08-26 19:16:31.211    0        5    1.0\n",
      "5      374472     6924 2020-08-26 19:15:47.232    0        5    1.0\n",
      "6      526578     4546 2020-11-02 16:31:18.543    0       22    1.0\n",
      "7      526578     8092 2020-11-02 16:34:33.794    0       22    1.0\n",
      "8      526578    17752 2020-11-02 16:43:04.022    0       22    1.0\n",
      "9      526578    14975 2020-11-02 16:42:02.287    0       22    1.0\n",
      "computed\n",
      "   session_id  item_id                    date  idx  idx_max  count\n",
      "0      663204    12492 2020-12-18 21:26:47.986    0        0    1.0\n",
      "1       85375     3299 2020-03-13 19:36:15.507    0        1    1.0\n",
      "2      374472    17411 2020-08-26 19:20:32.049    0        2    1.0\n",
      "3      526578    11229 2020-11-02 17:16:45.920    0        3    1.0\n",
      "4       66630    11568 2020-02-26 18:27:44.114    0        4    1.0\n",
      "5      192688    18172 2020-05-18 12:52:09.764    0        5    1.0\n",
      "6      895749     1512 2021-04-20 19:46:42.594    0        6    1.0\n",
      "7      257246    12205 2020-06-21 10:33:22.535    0        7    1.0\n",
      "8      789144     2124 2021-03-01 15:17:04.264    0        8    1.0\n",
      "9      580394     6925 2020-11-27 20:46:08.951    0        9    1.0\n",
      "computed\n",
      "   session_id  item_id                    date  idx  idx_max  count\n",
      "0      929236      417 2021-05-05 13:19:15.147    0        5    1.0\n",
      "1      929236     3054 2021-05-05 14:13:21.645    0        5    1.0\n",
      "2      929236     2780 2021-05-05 13:19:54.211    0        5    1.0\n",
      "3      929236    14829 2021-05-05 13:18:49.495    0        5    1.0\n",
      "4      929236     3746 2021-05-05 14:03:43.401    0        5    1.0\n",
      "5      929236     1139 2021-05-05 13:18:20.994    0        5    1.0\n",
      "6      984653     2950 2021-05-27 10:14:06.491    0       13    1.0\n",
      "7      984653     3491 2021-05-27 10:14:01.136    0       13    1.0\n",
      "8      984653     2821 2021-05-27 10:13:55.930    0       13    1.0\n",
      "9      984653     3491 2021-05-27 10:13:40.996    0       13    1.0\n",
      "computed\n",
      "   session_id  item_id                    date  idx  idx_max  count\n",
      "0      929236     3732 2021-05-05 14:15:07.278    0        0    1.0\n",
      "1      984653     4579 2021-05-27 10:24:05.043    0        1    1.0\n",
      "2      998452     1605 2021-05-31 13:44:52.368    0        2    1.0\n",
      "3      928718      806 2021-05-05 10:11:06.926    0        3    1.0\n",
      "4      980028     4503 2021-05-25 16:24:30.224    0        4    1.0\n",
      "5      970090     2620 2021-05-21 18:12:17.106    0        5    1.0\n",
      "6      987395     1972 2021-05-28 08:35:35.820    0        6    1.0\n",
      "7      952246     2725 2021-05-14 19:53:25.760    0        7    1.0\n",
      "8      951522     1790 2021-05-14 17:48:41.203    0        8    1.0\n",
      "9      961516     2483 2021-05-18 13:16:44.633    0        9    1.0\n",
      "computed\n"
     ]
    }
   ],
   "source": [
    "train_sessions_seen = get_URM_temporal_decay_within_session()\n",
    "train_bought = get_URM_temporal_decay_within_session(\"train_purchases_train_split_mapped.csv\")\n",
    "\n",
    "valid_sessions_seen= get_URM_temporal_decay_within_session(\"train_sessions_valid_split_mapped.csv\")\n",
    "valid_bought = get_URM_temporal_decay_within_session(\"train_purchases_valid_split_mapped.csv\")\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_train_seen.npz\"), train_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_train_bought.npz\"), train_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_valid_seen.npz\"), valid_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_valid_bought.npz\"), valid_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_train_full.npz\"), train_sessions_seen+train_bought)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_valid_full.npz\"), valid_sessions_seen+valid_bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions_seen[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM_test_temporal_decay_within_session(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False,temperature=5):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    \n",
    "    \n",
    "    df_URM[\"idx\"] = df_URM.index\n",
    "\n",
    "    temp=df_URM.groupby([\"session_id\"])[\"idx\"].max().reset_index()\n",
    "    \n",
    "    temp.rename(columns={\"idx\":\"idx_max\"},inplace=True)\n",
    "    df_URM=df_URM.merge(temp,on=\"session_id\",how=\"left\")\n",
    "    df_URM[\"idx\"]=df_URM[\"idx_max\"]-df_URM[\"idx\"] + 1 \n",
    "    df_URM[\"count\"] = df_URM[\"idx\"].apply(lambda x: np.exp(-x/temperature))\n",
    "\n",
    "    print(df_URM.head(10))\n",
    "\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)))\n",
    "\n",
    "    \n",
    "\n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                    date  idx  idx_max     count\n",
      "0          26     3404 2021-06-16 09:53:54.158    1        0  0.818731\n",
      "1         200     3037 2021-06-25 12:23:40.811    4        4  0.449329\n",
      "2         200     3037 2021-06-25 12:24:36.631    3        4  0.548812\n",
      "3         200     1468 2021-06-25 12:24:41.677    2        4  0.670320\n",
      "4         200      887 2021-06-25 12:24:50.692    1        4  0.818731\n",
      "5         205     1484 2021-06-11 00:28:07.058    1        5  0.818731\n",
      "6         495     1250 2021-06-14 22:13:06.741    1        6  0.818731\n",
      "7         521     4673 2021-06-19 13:50:03.090    1        7  0.818731\n",
      "8         587     3945 2021-06-01 16:43:22.800    1        8  0.818731\n",
      "9         721     2464 2021-06-19 18:46:57.263    1        9  0.818731\n",
      "   session_id  item_id                    date  idx  idx_max     count\n",
      "0          61     4785 2021-06-01 08:12:39.664    1        0  0.818731\n",
      "1          96     2107 2021-06-19 17:48:05.227    5        5  0.367879\n",
      "2          96     3251 2021-06-19 17:49:08.589    4        5  0.449329\n",
      "3          96      884 2021-06-19 17:49:15.838    3        5  0.548812\n",
      "4          96       89 2021-06-19 17:49:20.880    2        5  0.670320\n",
      "5          96     1252 2021-06-19 17:56:21.317    1        5  0.818731\n",
      "6         185     3133 2021-06-07 15:53:21.640    5       10  0.367879\n",
      "7         185     3767 2021-06-07 15:53:29.483    4       10  0.449329\n",
      "8         185     3767 2021-06-07 15:53:53.069    3       10  0.548812\n",
      "9         185     3133 2021-06-07 15:54:07.491    2       10  0.670320\n"
     ]
    }
   ],
   "source": [
    "test_leaderboard = get_URM_test_temporal_decay_within_session(file=\"test_leaderboard_sessions_mapped.csv\")\n",
    "\n",
    "test_final = get_URM_test_temporal_decay_within_session(file=\"test_final_sessions_mapped.csv\")\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_test_leaderboard.npz\"), test_leaderboard)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_test_final.npz\"), test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.02791218733398"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_leaderboard[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__==\"2.8.2\",\"tf_version is wrong\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('sub_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61f38fddaed46afda7c40a5798d4631266e18af1d335aa6f772dc3ed9b8ab549"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
